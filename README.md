# Multi-Source-Transfer-Learning
Normally transfer learning is done at a whole network level or the transfer is upto layer and latter layers are trained suitably.
Whereas in this work we propose a transfer to a target task from multiple CNNs. We consider the granularity of, 1. Network, 2. Layer and 3. Filter level.
Soon we will share the code for the following works: 

"Bank of Weight Filters for Deep CNNs." Kumaraswamy, Suresh Kirthi, P. S. Sastry, and Kalpathi Ramakrishnan, Asian Conference on Machine Learning. PMLR, 2016.

"Multi-source Subnetwork-level Transfer in CNNs Using Filter-Trees." 2018, Kumaraswamy, Suresh Kirthi, P. S. Sastry, and Kalpathi Ramakrishnan. , International Joint Conference on Neural Networks (IJCNN). IEEE, 2018

Caffe and MATLAB code coming soon...
